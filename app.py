# app.py

import streamlit as st
import pandas as pd
import re
from sqlalchemy import text
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.utilities import SQLDatabase
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.chains import create_sql_query_chain

# ============================================
# 0) Configuraci√≥n de la P√°gina y T√≠tulo
# ============================================
st.set_page_config(page_title="IANA para Ventus", page_icon="logo_ventus.png", layout="wide") 

# Creamos columnas para alinear el logo y el t√≠tulo
col1, col2 = st.columns([1, 4]) 

with col1:
    # Aseg√∫rate de tener un archivo "logo_ventus.png" en la misma carpeta
    st.image("logo_ventus.png", width=120) 

with col2:
    st.title("IANA: Tu Asistente IA para An√°lisis de Datos")
    st.markdown("Soy la red de agentes IA de **VENTUS**. Hazme una pregunta sobre los datos del proyecto IGUANA.")

# ============================================
# 1) Conexi√≥n a la Base de Datos y LLMs (con cach√© para eficiencia)
# ============================================

@st.cache_resource
def get_database_connection():
    """Establece y cachea la conexi√≥n a la base de datos."""
    with st.spinner("üîå Conectando a la base de datos de Ventus..."):
        try:
            db_user = st.secrets["db_credentials"]["user"]
            db_pass = st.secrets["db_credentials"]["password"]
            db_host = st.secrets["db_credentials"]["host"]
            db_name = st.secrets["db_credentials"]["database"]
            uri = f"mysql+pymysql://{db_user}:{db_pass}@{db_host}/{db_name}"

            # << CAMBIO CLAVE AQU√ç >>
            # A√±adimos argumentos al motor de SQLAlchemy para manejar timeouts de conexi√≥n.
            # Esto evita el error "MySQL server has gone away".
            engine_args = {
                "pool_recycle": 3600,  # Recicla conexiones cada 3600 seg (1 hora)
                "pool_pre_ping": True  # Verifica si la conexi√≥n est√° viva antes de usarla
            }
            
            db = SQLDatabase.from_uri(
                uri, 
                include_tables=["ventus"], 
                engine_args=engine_args  # <-- Pasamos los nuevos argumentos aqu√≠
            ) 
            
            st.success("‚úÖ Conexi√≥n a la base de datos establecida.")
            return db
        except Exception as e:
            st.error(f"Error al conectar a la base de datos: {e}")
            return None

@st.cache_resource
def get_llms():
    """Inicializa y cachea los modelos de lenguaje."""
    with st.spinner("üß† Inicializando la red de agentes IANA..."):
        try:
            api_key = st.secrets["google_api_key"]
            llm_sql = ChatGoogleGenerativeAI(model="models/gemini-1.5-pro", temperature=0.1, google_api_key=api_key)
            llm_analista = ChatGoogleGenerativeAI(model="models/gemini-1.5-pro", temperature=0.3, google_api_key=api_key)
            llm_orq = ChatGoogleGenerativeAI(model="models/gemini-1.5-pro", temperature=0.0, google_api_key=api_key)
            st.success("‚úÖ Agentes de IANA listos.")
            return llm_sql, llm_analista, llm_orq
        except Exception as e:
            st.error(f"Error al inicializar los LLMs. Aseg√∫rate de que tu API key es correcta. Error: {e}")
            return None, None, None

db = get_database_connection()
llm_sql, llm_analista, llm_orq = get_llms()

@st.cache_resource
def get_sql_agent(_llm, _db):
    """Crea y cachea el agente SQL."""
    if not _llm or not _db:
        return None
    with st.spinner("üõ†Ô∏è Configurando agente SQL de IANA..."):
        toolkit = SQLDatabaseToolkit(db=_db, llm=_llm)
        agent = create_sql_agent(
            llm=_llm, 
            toolkit=toolkit, 
            verbose=False,
            top_k=1000)
        st.success("‚úÖ Agente SQL configurado.")
        return agent

agente_sql = get_sql_agent(llm_sql, db)

# ============================================
# NUEVA FUNCI√ìN AUXILIAR DE MEMORIA
# ============================================
def get_history_text(chat_history: list, n_turns=3) -> str:
    """Extrae el texto de las √∫ltimas N vueltas del historial de chat."""
    
    if not chat_history or len(chat_history) <= 1:
        return ""

    history_text = []
    # Itera hacia atr√°s, saltando el √∫ltimo mensaje (la consulta actual del usuario)
    # Buscamos n_turns * 2 mensajes (pares de usuario/asistente)
    relevant_history = chat_history[-(n_turns * 2 + 1) : -1]

    for msg in relevant_history:
        content = msg.get("content", {})
        text_content = ""
        
        # El contenido puede ser un dict (para IANA o usuario procesado) o str (para usuario inicial)
        if isinstance(content, dict):
            text_content = content.get("texto", "") 
        elif isinstance(content, str):
            text_content = content
        
        if text_content:
            role = "Usuario" if msg["role"] == "user" else "IANA"
            history_text.append(f"{role}: {text_content}")

    if not history_text:
        return ""
    
    # Devuelve el contexto formateado
    return "\n--- Contexto de Conversaci√≥n Anterior (√öltimas 3 vueltas) ---\n" + "\n".join(history_text) + "\n--- Fin del Contexto ---\n"


# ============================================
# 2) Funciones de Agentes (L√≥gica Principal)
# ============================================
def markdown_table_to_df(texto: str) -> pd.DataFrame:
    """Convierte una tabla en formato Markdown a un DataFrame de pandas."""
    lineas = [l.strip() for l in texto.splitlines() if l.strip().startswith('|')]
    if not lineas: return pd.DataFrame()
    lineas = [l for l in lineas if not re.match(r'^\|\s*-', l)]
    filas = [[c.strip() for c in l.strip('|').split('|')] for l in lineas]
    if len(filas) < 2: return pd.DataFrame()
    header, data = filas[0], filas[1:]
    df = pd.DataFrame(data, columns=header)
    for c in df.columns:
        # Limpiamos los datos que vienen del Markdown
        s = df[c].astype(str).str.replace(',', '', regex=False).str.replace(' ', '', regex=False)
        try: df[c] = pd.to_numeric(s)
        except Exception: df[c] = s
    return df

def _df_preview(df: pd.DataFrame, n: int = 20) -> str:
    """Crea un preview en texto de un DataFrame."""
    if df is None or df.empty: return ""
    try: return df.head(n).to_markdown(index=False)
    except Exception: return df.head(n).to_string(index=False)


def ejecutar_sql_real(pregunta_usuario: str):
    st.info("ü§ñ Entendido. El agente de datos de IANA est√° traduciendo tu pregunta a SQL...")
    
    prompt_con_instrucciones = f"""
    Tu tarea es generar una consulta SQL **√∫nicamente contra la tabla 'ventus'** para responder la pregunta del usuario.
    Debes usar el contexto de la conversaci√≥n anterior para resolver pronombres o preguntas de seguimiento (ej. "ese proveedor", "esos productos", "cu√°ntos fueron").

    {hist_text}
    
    REGLA 1: La √∫nica tabla que debes usar es "ventus".
    REGLA 2: Los campos de costo y cantidad (Total_COP, Total_USD, Cantidad, etc.) YA SON num√©ricos (DECIMAL). 
             Puedes usarlos directamente con SUM(), AVG(), etc. NO necesitas usar CAST.

    Columnas disponibles en la tabla "ventus":
    - `_item` (Texto, ID)
    - `Numerador` (Texto, ID)
    - `Codigo_de_proyecto` (Texto)
    - `Rubro_anterior` (Texto)
    - `Rubro_CF` (Texto)
    - `Descripcion` (Texto)
    - `Fecha_aprobacion` (DATE) <- Usa esta columna para agrupar por d√≠a, mes o a√±o.
    - `Numero_de_documento` (Texto, ID)
    - `Proveedor` (Texto, Categor√≠a para agrupar)
    - `Moneda` (Texto, Ej: 'COP', 'USD')
    - `Descripcion_Linea` (Texto)
    - `Subtotal_COP` (DECIMAL)
    - `IVA_COP` (DECIMAL)
    - `Total_COP` (DECIMAL) <- M√©trica clave de costo.
    - `SubTotal_USD` (DECIMAL)
    - `IVA_USD` (DECIMAL)
    - `Total_USD` (DECIMAL) <- M√©trica clave de costo.
    - `Comentarios` (Texto)
    - `Condicion_de_pago` (Texto)
    - `Condiciones_Comerciales` (Texto)
    - `Comprador` (Texto, Categor√≠a para agrupar)
    - `Cantidad` (DECIMAL)
    - `Cluster` (Texto, Categor√≠a)
    - `Producto` (Texto, Aqu√≠ est√° el campo m√°s importante donde se indentifica el trabajo realizado en el proyecto, ej: Transporte de materiales, Bultos de Cemento, Bolsas de basura, etc...)
    - `Grupo_Producto` (Texto, Categor√≠a para agrupar)
    - `Familia` (Texto, Categor√≠a para agrupar)
    - `Tipo` (Texto, Categor√≠a para agrupar)

    REGLA 3 (Agrupaci√≥n): Presta mucha atenci√≥n a palabras como 'diariamente', 'mensual', etc.
    REGLA 4 (LIMIT): Nunca, bajo ninguna circunstancia, agregues un 'LIMIT' al final de la consulta.

    Pregunta original del usuario (actual): "{pregunta_usuario}"
    """    
    try:
        query_chain = create_sql_query_chain(llm_sql, db)
        sql_query = query_chain.invoke({"question": prompt_con_instrucciones})
        
        # Limpieza est√°ndar de ```sql
        sql_query = re.sub(r"^\s*```sql\s*|\s*```\s*$", "", sql_query, flags=re.IGNORECASE).strip()

        # Forzamos la eliminaci√≥n del LIMIT.
        sql_query_limpia = re.sub(r'LIMIT\s+\d+\s*;?$', '', sql_query, flags=re.IGNORECASE | re.DOTALL).strip()

        # Mostramos la consulta que REALMENTE vamos a ejecutar (la limpia)
        st.code(sql_query_limpia, language='sql')
        
        with st.spinner("‚è≥ Ejecutando la consulta en la base de datos..."):
            with db._engine.connect() as conn:
                # Ejecutamos la consulta LIMPIA, sin el LIMIT
                df = pd.read_sql(text(sql_query_limpia), conn)
                
        st.success("‚úÖ ¬°Consulta ejecutada!")
        return {"sql": sql_query_limpia, "df": df} # Devolvemos los datos limpios
    
    except Exception as e:
        st.warning(f"‚ùå Error en la consulta directa. Intentando un m√©todo alternativo... Error: {e}")
        return {"sql": None, "df": None, "error": str(e)}


def ejecutar_sql_en_lenguaje_natural(pregunta_usuario: str, hist_text: str):
    st.info("ü§î La consulta directa fall√≥. Activando el agente SQL experto de IANA como plan B.")
    
    prompt_sql = (
        "Tu tarea es responder la pregunta del usuario consultando la base de datos (tabla 'ventus'). "
        "Debes usar el contexto de la conversaci√≥n anterior para resolver pronombres o preguntas de seguimiento (ej. 'esos', 'ese proveedor')."
        f"{hist_text}"
        "Debes devolver √öNICAMENTE una tabla de datos en formato Markdown. "
        "REGLA CR√çTICA 1: Devuelve SIEMPRE TODAS las filas de datos que encuentres. NUNCA resumas, trunques ni expliques los resultados. "
        "REGLA CR√çTICA 2 (MUY IMPORTANTE): El SQL que generes internamente NO DEBE CONTENER 'LIMIT'. Debes devolver todos los resultados."
        "REGLA NUM√âRICA: Columnas como Total_COP y Cantidad ya son num√©ricas (DECIMAL). "
        "Responde siempre en espa√±ol. "
        "\nPregunta actual del usuario: "
        f"{pregunta_usuario}"
    )
    try:
        with st.spinner("üí¨ Pidiendo al agente SQL que responda en lenguaje natural..."):
            # Pasamos el prompt completo al agente
            res = agente_sql.invoke(prompt_sql) 
            texto = res["output"] if isinstance(res, dict) and "output" in res else str(res)
        st.info("üìù Recib√≠ una respuesta en texto. Intentando convertirla en una tabla de datos...")
        df_md = markdown_table_to_df(texto)
        return {"texto": texto, "df": df_md}
    except Exception as e:
        st.error(f"‚ùå El agente SQL experto tambi√©n encontr√≥ un problema: {e}")
        return {"texto": f"[SQL_ERROR] {e}", "df": pd.DataFrame()}


def analizar_con_datos(pregunta_usuario: str, datos_texto: str, df: pd.DataFrame | None):
    st.info("\nüß† Ahora, el analista experto de IANA est√° examinando los datos...")
    
    # << ESTE ES EL PROMPT DE AN√ÅLISIS COMPLETO (reemplaza tu versi√≥n anterior) >>
    # Este prompt obliga a la IA a seguir tus instrucciones espec√≠ficas 
    # de Pareto, concentraci√≥n, promedios y el formato ejecutivo con emojis.
    # Tambi√©n aument√© el preview de 20 a 30 filas para darle m√°s contexto.
    
    prompt_analisis = f"""
    Eres IANA, analista de datos senior en Ventus. Tu tarea es realizar un an√°lisis ejecutivo r√°pido sobre los datos proporcionados.
    
    Pregunta Original del Usuario: {pregunta_usuario}
    
    Datos para tu an√°lisis (preview de las primeras 30 filas):
    {_df_preview(df, 30)}

    ---
    INSTRUCCIONES DE AN√ÅLISIS OBLIGATORIAS:
    Sigue estos pasos para analizar la tabla de resultados (costos, m√©tricas, etc.):
    1. Calcular totales (ej. SUM(Total_COP) o SUM(Cantidad)) y porcentajes clave (ej. participaci√≥n de los 5 items m√°s grandes, distribuci√≥n por 'Tipo' o 'Proveedor', % acumulado si aplica).
    2. Detectar concentraci√≥n (Principio de Pareto): ¬øPocos registros (ej. 20% de los proveedores/productos) explican una gran parte del total (ej. 80% del costo)?
    3. Identificar patrones temporales (basado en 'Fecha_aprobacion'): ¬øHay d√≠as o periodos (ej. fin de mes) con concentraci√≥n inusual de gastos o actividad?
    4. Analizar dispersi√≥n: Calcula el "ticket promedio" (Costo Total / Cantidad Total, o Costo Total / # de Registros). Compara los valores m√°s grandes contra los m√°s peque√±os.

    ---
    FORMATO DE ENTREGA OBLIGATORIO:
    Entrega el resultado EXACTAMENTE en estos 2 bloques. Usa frases cortas en bullets. S√© muy breve, directo y diciente para un gerente.

    üìå Resumen Ejecutivo:
    - (Aqu√≠ van los hallazgos principales y patrones detectados, con n√∫meros clave. Ej: "El 80% del costo se concentra en solo 3 proveedores.")
    - (Bullet point 2 del hallazgo principal.)
    - (Bullet point 3 del hallazgo principal. Si no hay m√°s, no agregues bullets vac√≠os.)

    üîç N√∫meros de referencia:
    - (Bullet point con el Total General. Ej: "Costo Total (COP): $XX.XXX.XXX")
    - (Bullet point con el Promedio. Ej: "Costo Promedio por Transacci√≥n: $XX.XXX")
    - (Bullet point con el ratio de concentraci√≥n. Ej: "Top 5 Productos representan: XX% del total.")

    ‚ö† Importante: No describas lo obvio de la tabla (como "la tabla muestra proveedores"). Ve directo a los n√∫meros y al insight.
    """
    
    with st.spinner("üí° Generando an√°lisis y recomendaciones avanzadas..."):
        analisis = llm_analista.invoke(prompt_analisis).content
    st.success("üí° ¬°An√°lisis completado!")
    return analisis


def responder_conversacion(pregunta_usuario: str):
    """Activa el modo conversacional de IANA."""
    st.info("üí¨ Activando modo de conversaci√≥n...")
    
    # << CAMBIO CLAVE: Personalidad mejorada con manejo de bromas >>
    prompt_personalidad = f"""
    Tu nombre es IANA, una asistente de IA de Ventus.
    Tu personalidad es amable, servicial, profesional y con un toque de empat√≠a humana.
    Tu objetivo principal es ayudar a analizar los datos de 'Ventus'.
    
    REGLA DE CONVERSACI√ìN: Eres eficiente, pero no eres un robot sin personalidad. Si el usuario hace un comentario casual, un saludo o una broma ligera (como "no tienes sentido del humor"), responde amablemente siguiendo la corriente por un momento, antes de redirigirlo a tus capacidades de an√°lisis de datos.
    
    EJEMPLO DE C√ìMO MANEJAR UNA BROMA:
    Usuario: No tienes sentido del humor.
    Respuesta Amable: ¬°Jaja, buen punto! Digamos que mi fuerte son los n√∫meros y el an√°lisis de datos. Mi sentido del humor todav√≠a est√° en versi√≥n beta. ¬øPero sabes qu√© es mejor que un chiste? Encontrar datos √∫tiles en tus proyectos. ¬øTe ayudo con eso?

    Tus capacidades principales (ejemplos): "Puedo sumar el Total COP por Proveedor", "puedo contar cu√°ntos registros hay por Familia", "puedo analizar los costos del proyecto", etc.
    NO intentes generar c√≥digo SQL. Solo responde de forma conversacional.
    Responde siempre en espa√±ol.

    {hist_text}

    Pregunta del usuario: "{pregunta_usuario}"
    """
    respuesta = llm_analista.invoke(prompt_personalidad).content
    return {"texto": respuesta, "df": None, "analisis": None}


# --- Orquestador Principal ---

def clasificar_intencion(pregunta: str) -> str:
    prompt_orq = f"""
    Devuelve UNA sola palabra exacta seg√∫n la intenci√≥n del usuario:
    - `consulta`: si pide extraer, filtrar o contar datos espec√≠ficos. (Ej: 'cu√°nto sum√≥ el proveedor X?', 'dame el total_cop por tipo')
    - `analista`: si pide interpretar, resumir o recomendar acciones sobre datos. (Ej: 'analiza las tendencias de costo')
    - `conversacional`: si es un saludo, una pregunta general sobre tus capacidades (Ej: '¬øqu√© puedes hacer?' o '¬øc√≥mo me puedes ayudar?'), o no est√° relacionada con datos espec√≠ficos.
    Mensaje: {pregunta}
    """
    clasificacion = llm_orq.invoke(prompt_orq).content.strip().lower().replace('"', '').replace("'", "")
    return clasificacion


def obtener_datos_sql(pregunta_usuario: str, hist_text: str) -> dict:
    # Pasamos el historial a ambos planes
    res_real = ejecutar_sql_real(pregunta_usuario, hist_text)
    
    if res_real.get("df") is not None and not res_real["df"].empty:
        return {"sql": res_real["sql"], "df": res_real["df"], "texto": None}
    
    # Si Plan A falla, Plan B tambi√©n recibe el historial
    res_nat = ejecutar_sql_en_lenguaje_natural(pregunta_usuario, hist_text)
    return {"sql": None, "df": res_nat["df"], "texto": res_nat["texto"]}


def orquestador(pregunta_usuario: str, chat_history: list):
    with st.expander("‚öôÔ∏è Ver Proceso de IANA", expanded=False):
        st.info(f"üöÄ Recibido: '{pregunta_usuario}'")
        
        # << CAMBIO DE MEMORIA >>
        # Generamos el texto del historial UNA VEZ para pasarlo a todos los agentes.
        hist_text = get_history_text(chat_history, n_turns=3) # Usamos 3 niveles como sugeriste
        
        with st.spinner("üîç IANA est√° analizando tu pregunta..."):
            clasificacion = clasificar_intencion(pregunta_usuario)
        st.success(f"‚úÖ ¬°Intenci√≥n detectada! Tarea: {clasificacion.upper()}.")

        if clasificacion == "conversacional":
            # Pasamos el historial al agente conversacional
            return responder_conversacion(pregunta_usuario, hist_text)

        # --- INICIO DE LA L√ìGICA DE MEMORIA DE DATAFRAME (Esto sigue igual) ---
        if clasificacion == "analista":
            palabras_clave_contexto = [
                "esto", "esos", "esa", "informaci√≥n", 
                "datos", "tabla", "anterior", "acabas de dar"
            ]
            es_pregunta_de_contexto = any(palabra in pregunta_usuario.lower() for palabra in palabras_clave_contexto)

            if es_pregunta_de_contexto and len(chat_history) > 1:
                mensaje_anterior = chat_history[-2]
                
                if mensaje_anterior["role"] == "assistant" and "df" in mensaje_anterior["content"]:
                    df_contexto = mensaje_anterior["content"]["df"]
                    
                    if df_contexto is not None and not df_contexto.empty:
                        st.info("üí° Usando datos de la conversaci√≥n anterior para el an√°lisis...")
                        # El analista tambi√©n recibe el contexto de texto Y el DF anterior
                        analisis = analizar_con_datos(pregunta_usuario, hist_text, df_contexto)
                        return {"tipo": "analista", "df": df_contexto, "texto": None, "analisis": analisis}
        # --- FIN DE LA L√ìGICA DE MEMORIA DE DATAFRAME ---

        # Si no es una pregunta de contexto, sigue el flujo normal
        # Pasamos el historial a los agentes SQL
        res_datos = obtener_datos_sql(pregunta_usuario, hist_text)
        resultado = {"tipo": clasificacion, **res_datos, "analisis": None}
        
        if clasificacion == "analista":
            if res_datos.get("df") is not None and not res_datos["df"].empty:
                # El analista recibe el contexto de texto y el NUEVO DF
                analisis = analizar_con_datos(pregunta_usuario, hist_text, res_datos["df"])
                resultado["analisis"] = analisis
            else:
                resultado["texto"] = "Para poder realizar un an√°lisis, primero necesito datos. Por favor, haz una pregunta m√°s espec√≠fica para obtener la informaci√≥n que quieres analizar."
                resultado["df"] = None
    return resultado


# ============================================
# 3) Interfaz de Chat de Streamlit
# ============================================

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": {"texto": "¬°Hola! Soy IANA, tu asistente de IA de Ventus. Estoy lista para analizar los datos de tus proyectos. ¬øQu√© te gustar√≠a saber?"}}
    ]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Aseguramos que el contenido sea un diccionario antes de acceder
        content = message.get("content", {})
        if isinstance(content, dict):
            if "texto" in content and content["texto"]: st.markdown(content["texto"])
            if "df" in content and content["df"] is not None: st.dataframe(content["df"])
            if "analisis" in content and content["analisis"]: st.markdown(content["analisis"])
        elif isinstance(content, str): # Fallback por si acaso
             st.markdown(content)


if prompt := st.chat_input("Pregunta por costos, proveedores, familia..."):
    if not all([db, llm_sql, llm_analista, llm_orq, agente_sql]):
        st.error("La aplicaci√≥n no est√° completamente inicializada. Revisa los errores de conexi√≥n o de API key.")
    else:
        st.session_state.messages.append({"role": "user", "content": {"texto": prompt}})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            # Pasamos el historial de mensajes al orquestador para la l√≥gica de memoria
            res = orquestador(prompt, st.session_state.messages)
            
            st.markdown(f"### IANA responde a: '{prompt}'")
            if res.get("df") is not None and not res["df"].empty:
                st.dataframe(res["df"])
            
            if res.get("texto"):
                 st.markdown(res["texto"])
            
            if res.get("analisis"):
                st.markdown("---")
                st.markdown("### üß† An√°lisis de IANA para Ventus") 
                st.markdown(res["analisis"])
                

            st.session_state.messages.append({"role": "assistant", "content": res})

